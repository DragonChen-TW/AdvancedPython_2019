p4

這是我們前面學的CNN
如果資料更複雜、問題更能處理
只用簡單的 CNN（這個版本大概是 LeNet）
是無法達到基本或更高的正確率

接著我們看看一些進階的架構

p5

CNN 套用不同大小、不同 stride 能壓縮資料
轉換形狀

如果我們套用多種大小、多種形狀呢
1x1 3x3 5x5 不同大小的壓縮方法
壓縮到同一個向量裡

p10

1x1 convolution
能夠節省計算數量
有興趣的人再自己找資料

p13
so 這就是 inception net
是 google 在 2014 提出的

p16 轉換成 pyTorch

p20 這裡要做一個concat
把所有放在一起
很幸運我們能直接使用 python list 合在一起

p25
學到這裡，你會開始感覺到你的 network 節點、複雜度不夠
（還有顯示卡運算速度和荷包不夠 QQ）
但，我們真的能一直加深、疊加嗎

p27
加深層次無法提高的原因
還等著被定義
可能是 梯度消失、考慮放棄 back propagation

p28
2015 年，ImageNet 迎來了一個里程碑
一個橫掃深度學習界的冠軍
Deep Residual Network 深度殘差網路
簡稱 ResNet

where is next



---
